{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd5af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlglot import parse_one, exp, parse\n",
    "from sqlglot.schema import MappingSchema\n",
    "from sqlglot.optimizer import optimize\n",
    "\n",
    "\n",
    "# read from file tpc-ds.sql and parse all create table statements\n",
    "with open(\"./tpc-ds.sql\") as f:\n",
    "    sql = f.read()\n",
    "    # trim leading comments\n",
    "    sql = \"\\n\".join([line for line in sql.split(\"\\n\") if not line.strip().startswith(\"--\")])\n",
    "\n",
    "schema = {}\n",
    "for statement in parse(sql):\n",
    "    if isinstance(statement, exp.Create):\n",
    "        table_name = statement.this.this.this.this\n",
    "\n",
    "        columns = {}\n",
    "        for col_def in statement.find_all(exp.ColumnDef):\n",
    "            col_name = col_def.this.name\n",
    "            col_type = col_def.args.get(\"kind\").sql()\n",
    "            columns[col_name] = col_type\n",
    "        \n",
    "        schema[table_name] = columns\n",
    "\n",
    "schema_obj = MappingSchema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aaf7df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH \"customer_total_return\" AS (\n",
      "  SELECT\n",
      "    DUMMY_KW_ONLY_SCALE(\"store_returns\".\"sr_customer_sk\") AS ctr_customer_sk,\n",
      "    DUMMY_KW_ONLY_SCALE(\"store_returns\".\"sr_store_sk\") AS ctr_store_sk,\n",
      "    SUM(\"store_returns\".\"sr_return_amt\") AS \"ctr_total_return\"\n",
      "  FROM \"store_returns\" AS \"store_returns\"\n",
      "  JOIN \"date_dim\" AS \"date_dim\"\n",
      "    ON \"date_dim\".\"d_date_sk\" = \"store_returns\".\"sr_returned_date_sk\"\n",
      "    AND \"date_dim\".\"d_year\" = 2001\n",
      "  GROUP BY\n",
      "    \"store_returns\".\"sr_customer_sk\",\n",
      "    \"store_returns\".\"sr_store_sk\"\n",
      "), \"_u_0\" AS (\n",
      "  SELECT\n",
      "    AVG(\"ctr2\".\"ctr_total_return\") * 1.2 AS \"_col_0\",\n",
      "    DUMMY_KW_ONLY_SCALE(\"ctr2\".\"ctr_store_sk\") AS _u_1\n",
      "  FROM \"customer_total_return\" AS \"ctr2\"\n",
      "  GROUP BY\n",
      "    \"ctr2\".\"ctr_store_sk\"\n",
      ")\n",
      "SELECT\n",
      "  DUMMY_TO_DECIMAL_STR(\"customer\".\"c_customer_id\") AS c_customer_id\n",
      "FROM \"customer_total_return\" AS \"ctr1\"\n",
      "JOIN \"store\" AS \"store\"\n",
      "  ON \"ctr1\".\"ctr_store_sk\" = \"store\".\"s_store_sk\" AND \"store\".\"s_state\" = 'TN'\n",
      "JOIN \"customer\" AS \"customer\"\n",
      "  ON \"ctr1\".\"ctr_customer_sk\" = \"customer\".\"c_customer_sk\"\n",
      "LEFT JOIN \"_u_0\" AS \"_u_0\"\n",
      "  ON \"_u_0\".\"_u_1\" = \"ctr1\".\"ctr_store_sk\"\n",
      "WHERE\n",
      "  \"_u_0\".\"_col_0\" < \"ctr1\".\"ctr_total_return\"\n",
      "ORDER BY\n",
      "  \"c_customer_id\"\n",
      "LIMIT 100\n"
     ]
    }
   ],
   "source": [
    "# read file content into query\n",
    "with open(\"/Users/henry/CS230-Project/query1.sql\") as f:\n",
    "    query = f.read()\n",
    "    # remove leading comments\n",
    "    query = \"\\n\".join([line for line in query.split(\"\\n\") if not line.strip().startswith(\"--\")])\n",
    "\n",
    "parsed = parse_one(query)\n",
    "optimized = optimize(parsed, schema=schema_obj)\n",
    "# print(optimized)\n",
    "\n",
    "if isinstance(optimized, exp.CTE):\n",
    "    main_query = optimized.this\n",
    "else:\n",
    "    main_query = optimized\n",
    "\n",
    "# helper: choose a dummy udf name based on the column type\n",
    "import inspect\n",
    "from decimal import Decimal\n",
    "from datetime import date, datetime\n",
    "import sys\n",
    "# ensure project root is on path when running in notebooks\n",
    "sys.path.insert(0, \"/Users/henry/CS230-Project\")\n",
    "import udf_insertion.dummy_udfs as dummy_udfs\n",
    "\n",
    "def normalize_type_name(t: str) -> str:\n",
    "    if not isinstance(t, str):\n",
    "        return t\n",
    "    return t.strip().upper()\n",
    "\n",
    "def target_python_type_from_col_type(col_type: str):\n",
    "    \"\"\"Map SQL-type text (from the schema) to a token describing the target type.\n",
    "\n",
    "    We return short tokens rather than Python classes so we can make\n",
    "    finer-grained decisions (e.g. decimal with scale).\n",
    "    \"\"\"\n",
    "    if not isinstance(col_type, str):\n",
    "        return \"unknown\"\n",
    "    t = normalize_type_name(col_type)\n",
    "\n",
    "    # Decimal/numeric with precision/scale: extract scale if present\n",
    "    if t.startswith(\"DECIMAL\") or t.startswith(\"NUMERIC\"):\n",
    "        # try to parse DECIMAL(p,s)\n",
    "        import re\n",
    "\n",
    "        m = re.search(r\"DECIMAL\\s*\\((\\d+)\\s*,\\s*(\\d+)\\)\", t)\n",
    "        if m:\n",
    "            precision = int(m.group(1))\n",
    "            scale = int(m.group(2))\n",
    "            return (\"decimal\", precision, scale)\n",
    "        # fallback: unknown-scale decimal\n",
    "        return (\"decimal\", None, None)\n",
    "\n",
    "    # integers\n",
    "    if any(k in t for k in (\"INT\", \"INTEGER\", \"LONG\", \"BIGINT\", \"TINYINT\", \"SMALLINT\")):\n",
    "        return \"int\"\n",
    "\n",
    "    # strings / char / varchar / text\n",
    "    if any(k in t for k in (\"CHAR\", \"STRING\", \"VARCHAR\", \"TEXT\", \"CHARACTER\")):\n",
    "        return \"str\"\n",
    "\n",
    "    # dates and timestamps\n",
    "    if \"DATE\" in t and \"TIMESTAMP\" not in t:\n",
    "        return \"date\"\n",
    "    if \"TIMESTAMP\" in t or \"TIME\" in t:\n",
    "        return \"datetime\"\n",
    "\n",
    "    # floating point\n",
    "    if any(k in t for k in (\"DOUBLE\", \"FLOAT\", \"REAL\")):\n",
    "        return \"float\"\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "def is_compatible_func(func, target_token):\n",
    "    \"\"\"Return True if `func` is a reasonable match for the desired target_token.\n",
    "\n",
    "    `target_token` is the value returned by `target_python_type_from_col_type`.\n",
    "    It may be a string like 'int'/'str'/'date'/'float' or a tuple for decimals\n",
    "    like (\"decimal\", precision, scale).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sig = inspect.signature(func)\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "    params = [p for p in sig.parameters.values() if p.kind in (p.POSITIONAL_ONLY, p.POSITIONAL_OR_KEYWORD)]\n",
    "    required = [p for p in params if p.default is p.empty]\n",
    "    # require at most one required positional param (the column)\n",
    "    if len(required) > 1:\n",
    "        return False\n",
    "\n",
    "    # if function has a return annotation, prefer matching that\n",
    "    ann = sig.return_annotation\n",
    "    if ann is not inspect._empty:\n",
    "        ann_name = getattr(ann, \"__name__\", str(ann)).lower()\n",
    "        # decimal tuple handling\n",
    "        if isinstance(target_token, tuple) and target_token[0] == \"decimal\":\n",
    "            if \"decimal\" in ann_name or \"str\" in ann_name:\n",
    "                return True\n",
    "            return False\n",
    "        # simple token cases\n",
    "        if isinstance(target_token, str):\n",
    "            if target_token == \"int\" and (ann is int or ann_name == \"int\"):\n",
    "                return True\n",
    "            if target_token == \"str\" and (ann is str or ann_name == \"str\"):\n",
    "                return True\n",
    "            if target_token == \"float\" and (ann is float or ann_name == \"float\"):\n",
    "                return True\n",
    "            if target_token == \"date\" and ann_name in (\"date\",):\n",
    "                return True\n",
    "            if target_token == \"datetime\" and ann_name in (\"datetime\",):\n",
    "                return True\n",
    "        # if annotation present but didn't match, avoid function\n",
    "        return False\n",
    "\n",
    "    # no return annotation: use name heuristics + parameter count\n",
    "    name = func.__name__.lower()\n",
    "    # decimal target\n",
    "    if isinstance(target_token, tuple) and target_token[0] == \"decimal\":\n",
    "        # prefer formatting helpers\n",
    "        if \"decimal\" in name or \"to_decimal\" in name or \"to_decimal_str\" in name:\n",
    "            return True\n",
    "        # allow numeric helpers that accept one arg\n",
    "        return len(required) <= 1\n",
    "\n",
    "    if target_token == \"int\":\n",
    "        if any(k in name for k in (\"int\", \"add\", \"scale\")):\n",
    "            return True\n",
    "    if target_token == \"str\":\n",
    "        if any(k in name for k in (\"str\", \"concat\", \"unescape\", \"regex\", \"replace\")):\n",
    "            return True\n",
    "    if target_token == \"date\":\n",
    "        if \"date\" in name or \"timestamp\" in name:\n",
    "            return True\n",
    "    if target_token == \"datetime\":\n",
    "        if \"timestamp\" in name or \"time\" in name:\n",
    "            return True\n",
    "    if target_token == \"float\":\n",
    "        if any(k in name for k in (\"float\", \"double\", \"real\")):\n",
    "            return True\n",
    "\n",
    "    # conservative fallback: allow functions that accept <=1 required arg\n",
    "    return len(required) <= 1\n",
    "\n",
    "def choose_udf_name_for_col_type(col_type: str) -> str:\n",
    "    token = target_python_type_from_col_type(col_type)\n",
    "    # prefer functions in the provided registry that match\n",
    "    for f in dummy_udfs.all_simple_functions:\n",
    "        if is_compatible_func(f, token):\n",
    "            return f\"dummy_{f.__name__}\"\n",
    "    # if we have a decimal with small scale, prefer to_decimal_str if present\n",
    "    if isinstance(token, tuple) and token[0] == \"decimal\":\n",
    "        for f in dummy_udfs.all_simple_functions:\n",
    "            if f.__name__ == \"to_decimal_str\":\n",
    "                return \"dummy_to_decimal_str\"\n",
    "    # fallback: identity (no-op) function name\n",
    "    return \"dummy_identity\"\n",
    "\n",
    "for select in main_query.find_all(exp.Select):\n",
    "    new_expressions = []\n",
    "\n",
    "    for expr in select.expressions:\n",
    "        if isinstance(expr, exp.Alias) and isinstance(expr.this, exp.Column):\n",
    "            alias_name = expr.alias\n",
    "            column_name = expr.this.name\n",
    "\n",
    "            # try to read the resolved column type from the optimizer metadata (sqlglot stores a _type on Column nodes)\n",
    "            try:\n",
    "                col_type = expr.this._type.sql()\n",
    "            except Exception:\n",
    "                col_type = None\n",
    "\n",
    "            udf_name = choose_udf_name_for_col_type(col_type) if col_type else 'dummy_identity'\n",
    "            udf_node = exp.Anonymous(this=udf_name, expressions=[expr.this.copy()])\n",
    "            alias_node = exp.Alias(this=udf_node, alias=alias_name)\n",
    "            new_expressions.append(alias_node)\n",
    "        else:\n",
    "            new_expressions.append(expr)\n",
    "\n",
    "    select.set(\"expressions\", new_expressions)\n",
    "\n",
    "print(optimized.sql(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b8ab5",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "This notebook parses a SQL schema and a query with `sqlglot`, runs the optimizer with the schema,\n",
    "then walks the optimized AST and wraps aliased column expressions in an anonymous UDF call while preserving aliases.\n",
    "The next cell demonstrates how to use a configurable `udf_name` and shows a before/after example on a small query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d15fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original SQL ---\n",
      "SELECT a AS a_alias, b FROM my_table;\n",
      "\n",
      "--- Transformed SQL (udf_name=my_udf) ---\n",
      "SELECT\n",
      "  MY_UDF(\"my_table\".\"a\") AS a_alias,\n",
      "  MY_UDF(\"my_table\".\"b\") AS b\n",
      "FROM \"my_table\" AS \"my_table\"\n"
     ]
    }
   ],
   "source": [
    "# Demo: configurable udf_name and small before/after example\n",
    "from sqlglot import parse_one, exp\n",
    "from sqlglot.optimizer import optimize\n",
    "from sqlglot.schema import MappingSchema\n",
    "\n",
    "def wrap_columns_with_udf_in_sql(query, udf_name, schema_obj):\n",
    "    parsed = parse_one(query)\n",
    "    optimized = optimize(parsed, schema=schema_obj)\n",
    "    if isinstance(optimized, exp.CTE):\n",
    "        main_query = optimized.this\n",
    "    else:\n",
    "        main_query = optimized\n",
    "    for select in main_query.find_all(exp.Select):\n",
    "        new_expressions = []\n",
    "        for expr in select.expressions:\n",
    "            if isinstance(expr, exp.Alias) and isinstance(expr.this, exp.Column):\n",
    "                udf_node = exp.Anonymous(this=udf_name, expressions=[expr.this.copy()])\n",
    "                alias_node = exp.Alias(this=udf_node, alias=expr.alias)\n",
    "                new_expressions.append(alias_node)\n",
    "            else:\n",
    "                new_expressions.append(expr)\n",
    "        select.set(\"expressions\", new_expressions)\n",
    "    return optimized.sql(pretty=True)\n",
    "\n",
    "# create a tiny schema for the demo (doesn't depend on tpc-ds)\n",
    "demo_schema = MappingSchema({'my_table': {'a': 'INT', 'b': 'STRING'}})\n",
    "\n",
    "sample_query = 'SELECT a AS a_alias, b FROM my_table;'\n",
    "print('--- Original SQL ---')\n",
    "print(sample_query)\n",
    "print('\\n--- Transformed SQL (udf_name=my_udf) ---')\n",
    "print(wrap_columns_with_udf_in_sql(sample_query, udf_name='my_udf', schema_obj=demo_schema))\n",
    "# print('--- Transformed SQL (udf_name=custom_fn) ---')\n",
    "# print(wrap_columns_with_udf_in_sql(sample_query, udf_name='custom_fn', schema_obj=demo_schema))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
