{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecd5af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlglot import parse_one, exp, parse\n",
    "from sqlglot.schema import MappingSchema\n",
    "from sqlglot.optimizer import optimize\n",
    "\n",
    "\n",
    "# read from file tpc-ds.sql and parse all create table statements\n",
    "with open(\"./tpc-ds.sql\") as f:\n",
    "    sql = f.read()\n",
    "    # trim leading comments\n",
    "    sql = \"\\n\".join([line for line in sql.split(\"\\n\") if not line.strip().startswith(\"--\")])\n",
    "\n",
    "schema = {}\n",
    "for statement in parse(sql):\n",
    "    if isinstance(statement, exp.Create):\n",
    "        table_name = statement.this.this.this.this\n",
    "\n",
    "        columns = {}\n",
    "        for col_def in statement.find_all(exp.ColumnDef):\n",
    "            col_name = col_def.this.name\n",
    "            col_type = col_def.args.get(\"kind\").sql()\n",
    "            columns[col_name] = col_type\n",
    "        \n",
    "        schema[table_name] = columns\n",
    "\n",
    "schema_obj = MappingSchema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aaf7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file content into query\n",
    "with open(\"/Users/henry/CS230-Project/query1.sql\") as f:\n",
    "    query = f.read()\n",
    "    # remove leading comments\n",
    "    query = \"\\n\".join([line for line in query.split(\"\\n\") if not line.strip().startswith(\"--\")])\n",
    "\n",
    "parsed = parse_one(query)\n",
    "optimized = optimize(parsed, schema=schema_obj)\n",
    "# print(optimized)\n",
    "\n",
    "if isinstance(optimized, exp.CTE):\n",
    "    main_query = optimized.this\n",
    "else:\n",
    "    main_query = optimized\n",
    "\n",
    "# helper: choose a dummy udf name based on the column type\n",
    "import inspect\n",
    "from decimal import Decimal\n",
    "from datetime import date, datetime\n",
    "import sys\n",
    "# ensure project root is on path when running in notebooks\n",
    "sys.path.insert(0, \"/Users/henry/CS230-Project\")\n",
    "import udf_insertion.dummy_udfs as dummy_udfs\n",
    "\n",
    "def normalize_type_name(t: str) -> str:\n",
    "    if not isinstance(t, str):\n",
    "        return t\n",
    "    return t.strip().upper()\n",
    "\n",
    "def target_python_type_from_col_type(col_type: str):\n",
    "    \"\"\"Map SQL-type text (from the schema) to a token describing the target type.\n",
    "\n",
    "    We return short tokens rather than Python classes so we can make\n",
    "    finer-grained decisions (e.g. decimal with scale).\n",
    "    \"\"\"\n",
    "    if not isinstance(col_type, str):\n",
    "        return \"unknown\"\n",
    "    t = normalize_type_name(col_type)\n",
    "\n",
    "    # Decimal/numeric with precision/scale: extract scale if present\n",
    "    if t.startswith(\"DECIMAL\") or t.startswith(\"NUMERIC\"):\n",
    "        # try to parse DECIMAL(p,s)\n",
    "        import re\n",
    "\n",
    "        m = re.search(r\"DECIMAL\\s*\\((\\d+)\\s*,\\s*(\\d+)\\)\", t)\n",
    "        if m:\n",
    "            precision = int(m.group(1))\n",
    "            scale = int(m.group(2))\n",
    "            return (\"decimal\", precision, scale)\n",
    "        # fallback: unknown-scale decimal\n",
    "        return (\"decimal\", None, None)\n",
    "\n",
    "    # integers\n",
    "    if any(k in t for k in (\"INT\", \"INTEGER\", \"LONG\", \"BIGINT\", \"TINYINT\", \"SMALLINT\")):\n",
    "        return \"int\"\n",
    "\n",
    "    # strings / char / varchar / text\n",
    "    if any(k in t for k in (\"CHAR\", \"STRING\", \"VARCHAR\", \"TEXT\", \"CHARACTER\")):\n",
    "        return \"str\"\n",
    "\n",
    "    # dates and timestamps\n",
    "    if \"DATE\" in t and \"TIMESTAMP\" not in t:\n",
    "        return \"date\"\n",
    "    if \"TIMESTAMP\" in t or \"TIME\" in t:\n",
    "        return \"datetime\"\n",
    "\n",
    "    # floating point\n",
    "    if any(k in t for k in (\"DOUBLE\", \"FLOAT\", \"REAL\")):\n",
    "        return \"float\"\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "def is_compatible_func(func, target_token):\n",
    "    \"\"\"Return True if `func` is a reasonable match for the desired target_token.\n",
    "\n",
    "    This is a permissive heuristic used for choosing a dummy UDF. It prefers\n",
    "    functions with at most one required positional argument and then uses\n",
    "    return-annotation and name-based signals to bias selection.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sig = inspect.signature(func)\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "    params = [\n",
    "        p\n",
    "        for p in sig.parameters.values()\n",
    "        if p.kind in (p.POSITIONAL_ONLY, p.POSITIONAL_OR_KEYWORD)\n",
    "    ]\n",
    "    required = [p for p in params if p.default is p.empty]\n",
    "    # prefer functions with <= 1 required positional arg\n",
    "    if len(required) > 1:\n",
    "        return False\n",
    "\n",
    "    # if function has a return annotation, prefer matching that\n",
    "    ann = sig.return_annotation\n",
    "    if ann is not inspect._empty:\n",
    "        ann_name = getattr(ann, \"__name__\", str(ann)).lower()\n",
    "        # decimal tuple handling\n",
    "        if isinstance(target_token, tuple) and target_token[0] == \"decimal\":\n",
    "            if \"decimal\" in ann_name or \"str\" in ann_name or \"float\" in ann_name:\n",
    "                return True\n",
    "            return False\n",
    "        if isinstance(target_token, str):\n",
    "            if target_token == \"int\" and (ann is int or ann_name == \"int\"):\n",
    "                return True\n",
    "            if target_token == \"str\" and (ann is str or ann_name == \"str\"):\n",
    "                return True\n",
    "            if target_token == \"float\" and (ann is float or ann_name == \"float\"):\n",
    "                return True\n",
    "            if target_token == \"date\" and \"date\" in ann_name:\n",
    "                return True\n",
    "            if target_token == \"datetime\" and \"datetime\" in ann_name:\n",
    "                return True\n",
    "            if target_token == \"bool\" and (ann is bool or \"bool\" in ann_name):\n",
    "                return True\n",
    "            if target_token == \"bytes\" and (ann is bytes or \"bytes\" in ann_name):\n",
    "                return True\n",
    "            if target_token == \"list\" and \"list\" in ann_name:\n",
    "                return True\n",
    "        # if annotation present but didn't match, avoid function\n",
    "        return False\n",
    "\n",
    "    # no return annotation: use name heuristics + parameter count\n",
    "    name = func.__name__.lower()\n",
    "\n",
    "    if isinstance(target_token, tuple) and target_token[0] == \"decimal\":\n",
    "        if \"decimal\" in name or \"to_decimal\" in name or \"to_decimal_str\" in name:\n",
    "            return True\n",
    "        return len(required) <= 1\n",
    "\n",
    "    if target_token == \"int\":\n",
    "        if any(k in name for k in (\"int\", \"add\", \"sum\", \"scale\")):\n",
    "            return True\n",
    "    if target_token == \"str\":\n",
    "        if any(k in name for k in (\"str\", \"concat\", \"unescape\", \"regex\", \"replace\", \"base64\")):\n",
    "            return True\n",
    "    if target_token == \"date\":\n",
    "        if \"date\" in name or \"timestamp\" in name:\n",
    "            return True\n",
    "    if target_token == \"datetime\":\n",
    "        if \"timestamp\" in name or \"time\" in name:\n",
    "            return True\n",
    "    if target_token == \"float\":\n",
    "        if any(k in name for k in (\"float\", \"double\", \"real\", \"to_float\")):\n",
    "            return True\n",
    "    if target_token == \"bool\":\n",
    "        if any(k in name for k in (\"bool\", \"flag\", \"is_\")):\n",
    "            return True\n",
    "    if target_token == \"bytes\":\n",
    "        if any(k in name for k in (\"bytes\", \"base64\")):\n",
    "            return True\n",
    "    if target_token == \"list\":\n",
    "        if any(k in name for k in (\"list\", \"split\", \"map\", \"gen_id\")):\n",
    "            return True\n",
    "\n",
    "    # conservative fallback: allow functions that accept <=1 required arg\n",
    "    return len(required) <= 1\n",
    "\n",
    "\n",
    "def choose_udf_name_for_col_type(col_type: str) -> str:\n",
    "    \"\"\"Choose a dummy udf name for a given SQL column type string.\n",
    "\n",
    "    The function returns the string name of a dummy function prefixed with\n",
    "    `dummy_` (matching how functions are referenced in the registry).\n",
    "    \"\"\"\n",
    "    token = target_python_type_from_col_type(col_type)\n",
    "\n",
    "    # preferred name substrings per token (ordered)\n",
    "    prefs = {\n",
    "        \"int\": [\"sum_vars\", \"add\", \"scale\"],\n",
    "        \"str\": [\"concat\", \"to_decimal_str\", \"unescape\", \"regex\", \"replace\", \"bytes_to_base64\"],\n",
    "        \"date\": [\"timestamp_to_date\", \"date\"],\n",
    "        \"datetime\": [\"timestamp_to_date\", \"time\"],\n",
    "        \"float\": [\"to_float_or_none\", \"to_decimal_str\", \"float\"],\n",
    "        \"decimal\": [\"to_decimal_str\", \"to_float_or_none\"],\n",
    "        \"bool\": [\"bool_flag\", \"is_\"],\n",
    "        \"bytes\": [\"bytes_to_base64\", \"base64\"],\n",
    "        \"list\": [\"split_to_list\", \"map_to_upper\", \"gen_id_list\"],\n",
    "    }\n",
    "\n",
    "    # First try: find a function that is compatible according to signature+annotation\n",
    "    for f in dummy_udfs.all_simple_functions:\n",
    "        try:\n",
    "            if is_compatible_func(f, token):\n",
    "                return f\"dummy_{f.__name__}\"\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Second pass: name-preference matching (ignore signature)\n",
    "    key = None\n",
    "    if isinstance(token, tuple) and token[0] == \"decimal\":\n",
    "        key = \"decimal\"\n",
    "    elif isinstance(token, str):\n",
    "        key = token\n",
    "    if key and key in prefs:\n",
    "        for pname in prefs[key]:\n",
    "            for f in dummy_udfs.all_simple_functions:\n",
    "                if pname in f.__name__:\n",
    "                    return f\"dummy_{f.__name__}\"\n",
    "\n",
    "    # final fallbacks\n",
    "    for f in dummy_udfs.all_simple_functions:\n",
    "        if f.__name__ == \"dummy_identity\":\n",
    "            return \"dummy_identity\"\n",
    "\n",
    "    # absolute fallback\n",
    "    return \"dummy_identity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b415a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original SQL ---\n",
      "\n",
      "SELECT\n",
      "  i_item_id AS item_id,\n",
      "  i_current_price AS price,\n",
      "  i_item_desc AS description,\n",
      "  i_brand_id + 100 AS brand_id_adj,\n",
      "  CONCAT(i_item_id, '-', CAST(i_brand_id AS VARCHAR)) AS id_combo,\n",
      "  i_wholesale_cost * 1.10 AS cost_plus,\n",
      "  i_rec_start_date AS start_date,\n",
      "  REGEXP_REPLACE(i_item_desc, '\\s+', ' ') AS desc_clean,\n",
      "  UPPER(i_units) AS units_up,\n",
      "  (i_manager_id IS NOT NULL) AS has_manager\n",
      "FROM item;\n",
      "\n",
      "\n",
      "--- Transformed SQL ---\n",
      "\n",
      "SELECT\n",
      "  DUMMY_TO_DECIMAL_STR(\"item\".\"i_item_id\") AS item_id,\n",
      "  FLOAT(\"item\".\"i_current_price\") AS price,\n",
      "  HTML_UNESCAPE(\"item\".\"i_item_desc\") AS description,\n",
      "  DUMMY_KW_ONLY_SCALE(\"item\".\"i_brand_id\" + 100) AS brand_id_adj,\n",
      "  STR_JOIN(CONCAT(\"item\".\"i_item_id\", '-', CAST(\"item\".\"i_brand_id\" AS VARCHAR))) AS id_combo,\n",
      "  DUMMY_TO_DECIMAL_STR(\"item\".\"i_wholesale_cost\" * 1.10) AS cost_plus,\n",
      "  DUMMY_TIMESTAMP_TO_DATE(\"item\".\"i_rec_start_date\") AS start_date,\n",
      "  RE_SUB(REGEXP_REPLACE(\"item\".\"i_item_desc\", '\\s+', ' ')) AS desc_clean,\n",
      "  STR_UPPER(UPPER(\"item\".\"i_units\")) AS units_up,\n",
      "  DUMMY_KW_ONLY_SCALE(NOT \"item\".\"i_manager_id\" IS NULL) AS has_manager\n",
      "FROM \"item\" AS \"item\"\n"
     ]
    }
   ],
   "source": [
    "# Small schema-aware transplant demo using the TPC-DS `item` table (more complex, with stdlib wrappers)\n",
    "from sqlglot import parse_one, exp\n",
    "from sqlglot.optimizer import optimize\n",
    "import sys\n",
    "# ensure package importable in notebooks\n",
    "sys.path.insert(0, \"/Users/henry/CS230-Project\")\n",
    "import udf_insertion.dummy_udfs as dummy_udfs\n",
    "import html\n",
    "import base64\n",
    "import json\n",
    "import re\n",
    "\n",
    "# richer sample query using columns and expressions from the `item` table\n",
    "sample_query = '''\n",
    "SELECT\n",
    "  i_item_id AS item_id,\n",
    "  i_current_price AS price,\n",
    "  i_item_desc AS description,\n",
    "  i_brand_id + 100 AS brand_id_adj,\n",
    "  CONCAT(i_item_id, '-', CAST(i_brand_id AS VARCHAR)) AS id_combo,\n",
    "  i_wholesale_cost * 1.10 AS cost_plus,\n",
    "  i_rec_start_date AS start_date,\n",
    "  REGEXP_REPLACE(i_item_desc, '\\\\s+', ' ') AS desc_clean,\n",
    "  UPPER(i_units) AS units_up,\n",
    "  (i_manager_id IS NOT NULL) AS has_manager\n",
    "FROM item;\n",
    "'''\n",
    "\n",
    "print('--- Original SQL ---')\n",
    "print(sample_query)\n",
    "\n",
    "# parse + optimize with the already-built schema_obj (from earlier cell)\n",
    "parsed = parse_one(sample_query)\n",
    "optimized = optimize(parsed, schema=schema_obj)\n",
    "\n",
    "# Reuse chooser if present; otherwise provide a fallback chooser\n",
    "try:\n",
    "    choose = choose_udf_name_for_col_type\n",
    "except NameError:\n",
    "    def choose(col_type):\n",
    "        if not col_type:\n",
    "            return 'dummy_identity'\n",
    "        t = col_type.upper()\n",
    "        if 'DECIMAL' in t or 'NUMERIC' in t:\n",
    "            return 'dummy_to_decimal_str' if any(f.__name__ == 'to_decimal_str' for f in dummy_udfs.all_simple_functions) else 'dummy_identity'\n",
    "        if any(k in t for k in ('CHAR', 'STRING', 'VARCHAR', 'TEXT')):\n",
    "            return 'dummy_concat' if any(f.__name__ == 'concat' for f in dummy_udfs.all_simple_functions) else 'dummy_identity'\n",
    "        if any(k in t for k in ('INT', 'BIGINT', 'SMALLINT', 'TINYINT')):\n",
    "            return 'dummy_add' if any(f.__name__ == 'add' for f in dummy_udfs.all_simple_functions) else 'dummy_identity'\n",
    "        if any(k in t for k in ('DOUBLE','FLOAT','REAL')):\n",
    "            return 'dummy_to_decimal_str' if any(f.__name__ == 'to_decimal_str' for f in dummy_udfs.all_simple_functions) else 'dummy_identity'\n",
    "        return 'dummy_identity'\n",
    "\n",
    "# We will allow some aliases to be wrapped with stdlib-like wrappers rather than dummy_* names.\n",
    "# Map alias -> (module.function) to use as wrapper instead of a dummy function name.\n",
    "alias_stdlib_overrides = {\n",
    "    'description': 'html.unescape',\n",
    "    'desc_clean': 're.sub',\n",
    "    'id_combo': 'str.join',\n",
    "    'units_up': 'str.upper',\n",
    "    'price': 'float',\n",
    "}\n",
    "\n",
    "# apply schema-aware transplant: wrap aliased expressions that reference columns\n",
    "if isinstance(optimized, exp.CTE):\n",
    "    main_query = optimized.this\n",
    "else:\n",
    "    main_query = optimized\n",
    "\n",
    "chosen_map = {}\n",
    "used_stdlib = set()\n",
    "for select in main_query.find_all(exp.Select):\n",
    "    new_expressions = []\n",
    "    for expr in select.expressions:\n",
    "        # We're interested in Aliases (expression AS alias). For any aliased expression that\n",
    "        # references at least one Column, choose a UDF based on the first referenced column's type\n",
    "        if isinstance(expr, exp.Alias):\n",
    "            aliased_expr = expr.this\n",
    "            # find the first Column referenced inside the expression (if any)\n",
    "            cols = list(aliased_expr.find_all(exp.Column))\n",
    "            if cols:\n",
    "                first_col = cols[0]\n",
    "                try:\n",
    "                    col_type = first_col._type.sql()\n",
    "                except Exception:\n",
    "                    col_type = None\n",
    "                chosen = choose(col_type) if col_type else 'dummy_identity'\n",
    "                # if the alias is in our stdlib override map, prefer that wrapper\n",
    "                alias_name = expr.alias\n",
    "                if alias_name in alias_stdlib_overrides:\n",
    "                    stdlib_f = alias_stdlib_overrides[alias_name]\n",
    "                    # record and use a readable wrapper name in the SQL AST (dot replaced with _)\n",
    "                    wrapper_name = stdlib_f.replace('.', '_')\n",
    "                    udf_node = exp.Anonymous(this=wrapper_name, expressions=[aliased_expr.copy()])\n",
    "                    chosen_map[alias_name] = f\"stdlib:{stdlib_f}\"\n",
    "                    used_stdlib.add(stdlib_f)\n",
    "                else:\n",
    "                    # normal dummy function wrapping (keep the chosen name)\n",
    "                    udf_node = exp.Anonymous(this=chosen, expressions=[aliased_expr.copy()])\n",
    "                    chosen_map[alias_name] = chosen\n",
    "                alias_node = exp.Alias(this=udf_node, alias=alias_name)\n",
    "                new_expressions.append(alias_node)\n",
    "            else:\n",
    "                new_expressions.append(expr)\n",
    "        else:\n",
    "            new_expressions.append(expr)\n",
    "    select.set('expressions', new_expressions)\n",
    "\n",
    "# print('\\n--- Chosen UDF mapping (alias -> wrapper) ---')\n",
    "# for k, v in chosen_map.items():\n",
    "#     print(f\"{k} -> {v}\")\n",
    "\n",
    "# if used_stdlib:\n",
    "#     print('\\n--- Stdlib wrappers used (module.function) ---')\n",
    "#     for s in sorted(used_stdlib):\n",
    "#         print(s)\n",
    "\n",
    "print('\\n--- Transformed SQL ---\\n')\n",
    "print(optimized.sql(pretty=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
